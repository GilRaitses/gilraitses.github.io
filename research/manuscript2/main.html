<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Gil Raitses1, Devindi Goonawardhana2, Mirna Mihovilovic-Skanata2 1Syracuse University 2Department of Physics, Syracuse University" />
  <title>Quantitative Guidelines for Behavioral Phenotyping from Sparse Point-Process Data</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    div.abstract {
      margin: 2em 2em 2em 2em;
      text-align: left;
      font-size: 85%;
    }
    div.abstract-title {
      font-weight: bold;
      text-align: center;
      padding: 0;
      margin-bottom: 0.5em;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      border: none;
      border-top: 1px solid #1a1a1a;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Quantitative Guidelines for Behavioral Phenotyping
from Sparse Point-Process Data</h1>
<p class="author">Gil Raitses<sup>1</sup>, Devindi
Goonawardhana<sup>2</sup>, Mirna Mihovilovic-Skanata<sup>2</sup><br />
<sup>1</sup>Syracuse University<br />
<sup>2</sup>Department of Physics, Syracuse University</p>
<p class="date">December 2025</p>
<div class="abstract">
<div class="abstract-title">Abstract</div>
<p>Behavioral phenotyping requires reliable estimation of individual
differences from sparse event data. When larvae respond to light with
reorientation events, timing is governed by response kernels with
excitatory and inhibitory components. Population-level estimation is
robust, but individual-level inference is essential for genetic screens
and neural circuit mapping.</p>
<p>Individual kernel parameters are structurally non-identifiable under
standard experimental protocols. With approximately 20 events per larva,
maximum likelihood estimation produces estimates spanning the full
parameter range. The failure is not a sample size problem: the
inhibitory component suppresses events precisely when the excitatory
parameter would be most informative.</p>
<p>Design optimization reveals regime-dependent solutions. For
inhibition-dominated kernels, burst stimulation provides higher Fisher
Information. For excitatory kernels, continuous stimulation suffices.
Composite phenotypes derived from event statistics bypass kernel fitting
and achieve reliable recovery with current data.</p>
<p>These findings establish quantitative guidelines for sparse
point-process phenotyping. The framework applies broadly where validated
population models do not translate to individual-level inference.</p>
<p><strong>Keywords:</strong> behavioral phenotyping, point process,
identifiability, experimental design, <em>Drosophila</em> larvae</p>
</div>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a>
<ul>
<li><a href="#individual-analysis-challenges"
id="toc-individual-analysis-challenges">Individual Analysis
Challenges</a></li>
<li><a href="#reorientation-events-as-a-point-process"
id="toc-reorientation-events-as-a-point-process">Reorientation Events as
a Point Process</a></li>
<li><a href="#data-requirements-and-objectives"
id="toc-data-requirements-and-objectives">Data Requirements and
Objectives</a></li>
</ul></li>
<li><a href="#methods" id="toc-methods">Methods</a>
<ul>
<li><a href="#simulated-trajectory-generation"
id="toc-simulated-trajectory-generation">Simulated Trajectory
Generation</a></li>
<li><a href="#individual-level-kernel-fitting"
id="toc-individual-level-kernel-fitting">Individual-Level Kernel
Fitting</a></li>
<li><a href="#feature-extraction" id="toc-feature-extraction">Feature
Extraction</a></li>
<li><a href="#clustering-analysis"
id="toc-clustering-analysis">Clustering Analysis</a></li>
<li><a href="#cross-validation-and-cluster-validation"
id="toc-cross-validation-and-cluster-validation">Cross-Validation and
Cluster Validation</a></li>
<li><a href="#empirical-data-quality-control"
id="toc-empirical-data-quality-control">Empirical Data Quality
Control</a>
<ul>
<li><a href="#track-segmentation-validation"
id="toc-track-segmentation-validation">Track Segmentation
Validation</a></li>
<li><a href="#track-selection-criteria"
id="toc-track-selection-criteria">Track Selection Criteria</a></li>
<li><a href="#kernel-fitting-success-criteria"
id="toc-kernel-fitting-success-criteria">Kernel Fitting Success
Criteria</a></li>
</ul></li>
<li><a href="#comparison-of-simulated-vs.-empirical-data"
id="toc-comparison-of-simulated-vs.-empirical-data">Comparison of
Simulated vs. Empirical Data</a></li>
<li><a href="#psth-and-kernel-relationship"
id="toc-psth-and-kernel-relationship">PSTH and Kernel
Relationship</a></li>
<li><a href="#psth-construction-and-optimal-bin-width"
id="toc-psth-construction-and-optimal-bin-width">PSTH Construction and
Optimal Bin Width</a></li>
<li><a href="#fourier-neural-operator-for-kernel-recovery"
id="toc-fourier-neural-operator-for-kernel-recovery">Fourier Neural
Operator for Kernel Recovery</a></li>
<li><a href="#hierarchical-bayesian-model"
id="toc-hierarchical-bayesian-model">Hierarchical Bayesian
Model</a></li>
<li><a href="#sec:power_analysis" id="toc-sec:power_analysis">Power
Analysis</a>
<ul>
<li><a href="#two-types-of-errors" id="toc-two-types-of-errors">Two
Types of Errors</a></li>
<li><a href="#why-this-matters-for-phenotyping"
id="toc-why-this-matters-for-phenotyping">Why This Matters for
Phenotyping</a></li>
<li><a href="#simulation-based-power-calculation"
id="toc-simulation-based-power-calculation">Simulation-Based Power
Calculation</a></li>
<li><a href="#technical-details" id="toc-technical-details">Technical
Details</a></li>
<li><a href="#interpreting-the-results"
id="toc-interpreting-the-results">Interpreting the Results</a></li>
</ul></li>
<li><a href="#sec:ppc" id="toc-sec:ppc">Posterior Predictive
Checks</a></li>
<li><a href="#sec:model_selection" id="toc-sec:model_selection">Model
Selection</a></li>
<li><a href="#sec:loeo" id="toc-sec:loeo">Leave-One-Experiment-Out
Cross-Validation</a></li>
<li><a href="#statistical-analysis"
id="toc-statistical-analysis">Statistical Analysis</a></li>
</ul></li>
<li><a href="#results" id="toc-results">Results</a>
<ul>
<li><a href="#tracks-meet-quality-criteria"
id="toc-tracks-meet-quality-criteria">260 Tracks Meet Quality
Criteria</a></li>
<li><a
href="#individual-kernels-fit-successfully-with-high-apparent-separation"
id="toc-individual-kernels-fit-successfully-with-high-apparent-separation">Individual
Kernels Fit Successfully with High Apparent Separation</a>
<ul>
<li><a href="#four-clusters-emerge-with-99.6-classification-accuracy"
id="toc-four-clusters-emerge-with-99.6-classification-accuracy">Four
Clusters Emerge with 99.6% Classification Accuracy</a></li>
</ul></li>
<li><a
href="#round-trip-validation-reveals-phenotypes-are-not-recoverable"
id="toc-round-trip-validation-reveals-phenotypes-are-not-recoverable">Round-Trip
Validation Reveals Phenotypes Are Not Recoverable</a></li>
<li><a
href="#hierarchical-bayesian-model-reveals-population-homogeneity"
id="toc-hierarchical-bayesian-model-reveals-population-homogeneity">Hierarchical
Bayesian Model Reveals Population Homogeneity</a>
<ul>
<li><a href="#population-tau_1-0.63s-slower-than-original-estimate"
id="toc-population-tau_1-0.63s-slower-than-original-estimate">Population
<span class="math inline">\(\tau_1 = 0.63\)</span>s, Slower Than
Original Estimate</a></li>
<li><a href="#of-tracks-are-genuine-outliers"
id="toc-of-tracks-are-genuine-outliers">8.6% of Tracks Are Genuine
Outliers</a></li>
</ul></li>
<li><a href="#current-data-achieves-only-2030-power"
id="toc-current-data-achieves-only-2030-power">Current Data Achieves
Only 20–30% Power</a></li>
<li><a href="#optimal-design-depends-on-kernel-regime"
id="toc-optimal-design-depends-on-kernel-regime">Optimal Design Depends
on Kernel Regime</a></li>
</ul></li>
<li><a href="#discussion" id="toc-discussion">Discussion</a>
<ul>
<li><a
href="#structural-identifiability-explains-individual-phenotyping-failure"
id="toc-structural-identifiability-explains-individual-phenotyping-failure">Structural
Identifiability Explains Individual Phenotyping Failure</a></li>
<li><a href="#design-optimization-reveals-regime-dependent-solutions"
id="toc-design-optimization-reveals-regime-dependent-solutions">Design
Optimization Reveals Regime-Dependent Solutions</a></li>
<li><a href="#composite-phenotypes-bypass-kernel-fitting"
id="toc-composite-phenotypes-bypass-kernel-fitting">Composite Phenotypes
Bypass Kernel Fitting</a></li>
<li><a href="#condition-effects-confound-individual-differences"
id="toc-condition-effects-confound-individual-differences">Condition
Effects Confound Individual Differences</a></li>
<li><a
href="#dataset-composition-explains-population-parameter-differences"
id="toc-dataset-composition-explains-population-parameter-differences">Dataset
Composition Explains Population Parameter Differences</a></li>
<li><a href="#limitations" id="toc-limitations">Limitations</a></li>
</ul></li>
<li><a href="#conclusions" id="toc-conclusions">Conclusions</a>
<ul>
<li><a href="#recommendations-for-future-experiments"
id="toc-recommendations-for-future-experiments">Recommendations for
Future Experiments</a></li>
<li><a href="#recommended-phenotyping-approach"
id="toc-recommended-phenotyping-approach">Recommended Phenotyping
Approach</a></li>
<li><a href="#validation-requirements"
id="toc-validation-requirements">Validation Requirements</a></li>
<li><a href="#methodological-contribution"
id="toc-methodological-contribution">Methodological
Contribution</a></li>
</ul></li>
<li><a href="#app:clustering" id="toc-app:clustering">Detailed
Clustering Methodology</a>
<ul>
<li><a href="#clustering-stability-analysis"
id="toc-clustering-stability-analysis">Clustering Stability Analysis</a>
<ul>
<li><a href="#simulated-data-results"
id="toc-simulated-data-results">Simulated Data Results</a></li>
<li><a href="#empirical-data-results"
id="toc-empirical-data-results">Empirical Data Results</a></li>
</ul></li>
<li><a href="#cluster-validation-results"
id="toc-cluster-validation-results">Cluster Validation Results</a></li>
</ul></li>
<li><a href="#app:fno" id="toc-app:fno">Neural Operator Analysis</a>
<ul>
<li><a href="#validation-on-synthetic-data"
id="toc-validation-on-synthetic-data">Validation on Synthetic
Data</a></li>
<li><a href="#application-to-empirical-data"
id="toc-application-to-empirical-data">Application to Empirical
Data</a></li>
</ul></li>
<li><a href="#app:roundtrip" id="toc-app:roundtrip">Round-Trip
Validation Protocol</a>
<ul>
<li><a href="#simulation-protocol"
id="toc-simulation-protocol">Simulation Protocol</a></li>
<li><a href="#results-1" id="toc-results-1">Results</a></li>
</ul></li>
<li><a href="#app:pca" id="toc-app:pca">PCA Representation
Comparison</a></li>
<li><a href="#app:enhancements" id="toc-app:enhancements">Statistical
Enhancement Details</a>
<ul>
<li><a href="#power-analysis" id="toc-power-analysis">Power
Analysis</a></li>
<li><a href="#posterior-predictive-checks"
id="toc-posterior-predictive-checks">Posterior Predictive
Checks</a></li>
<li><a href="#model-comparison" id="toc-model-comparison">Model
Comparison</a></li>
<li><a href="#cross-experiment-generalization"
id="toc-cross-experiment-generalization">Cross-Experiment
Generalization</a></li>
</ul></li>
<li><a href="#acknowledgments"
id="toc-acknowledgments">Acknowledgments</a></li>
<li><a href="#data-availability" id="toc-data-availability">Data
Availability</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<h2 id="individual-analysis-challenges">Individual Analysis
Challenges</h2>
<p>Population-level analysis of larval reorientation behavior under
optogenetic stimulation has established that response timing follows a
gamma-difference kernel with two distinct timescales. The fast
excitatory component governs initial response probability, while a
slower inhibitory component suppresses reorientations over the following
seconds. The population-level model is robust across experimental
conditions. Individual larvae may exhibit distinct behavioral phenotypes
reflecting variability in sensorimotor integration. Characterizing
individual-level variability would enable identification of distinct
behavioral strategies and determination of sample sizes needed for
future phenotyping studies.</p>
<h2 id="reorientation-events-as-a-point-process">Reorientation Events as
a Point Process</h2>
<p>Larval locomotion alternates between forward runs and lateral turns.
At each moment during a run, the larva may initiate a turn with some
probability that depends on recent sensory history. These run-to-turn
transition times constitute a point process: discrete events at random
times in continuous time. The gamma-difference kernel <span
class="math inline">\(K(t)\)</span> modulates the instantaneous hazard
rate of initiating a turn as a function of time since LED onset.
Positive kernel values elevate turn probability; negative values
suppress turns.</p>
<p>The point process formulation has two implications. The appropriate
likelihood function rewards high hazard at observed event times and
penalizes high hazard during periods without events. Event times are not
exchangeable because their relationship to the stimulus protocol
matters, constraining valid bootstrap procedures.</p>
<h2 id="data-requirements-and-objectives">Data Requirements and
Objectives</h2>
<p>Individual-level inference from sparse event data poses a fundamental
challenge. The gamma-difference kernel has 6 free parameters: two
amplitudes <span class="math inline">\(A\)</span> and <span
class="math inline">\(B\)</span> controlling the strength of excitatory
and inhibitory components, and four shape parameters <span
class="math inline">\(\alpha_1\)</span>, <span
class="math inline">\(\beta_1\)</span>, <span
class="math inline">\(\alpha_2\)</span>, <span
class="math inline">\(\beta_2\)</span> that determine when each
component peaks and how quickly it decays. Typical 10–20 minute
recordings yield only 18–25 events per larva. The resulting
data-to-parameter ratio of 3:1 is far below the 10:1 commonly
recommended for reliable nonlinear estimation.</p>
<p>The central question is therefore not “Do phenotypes exist?” but “Can
phenotypes be reliably detected with available data?” Simulation-based
inference provides the framework: synthetic trajectories with known
parameters test whether fitting and clustering methods recover ground
truth. The study fits individual-level kernels to simulated and
empirical tracks, tests whether apparent clusters survive validation,
quantifies data requirements, and establishes whether population-level
or individual-level inference is appropriate.</p>
<h1 id="methods">Methods</h1>
<h2 id="simulated-trajectory-generation">Simulated Trajectory
Generation</h2>
<p>A total of 300 simulated trajectories (75 per condition) were
generated across four experimental conditions matching the main study’s
2×2 factorial design: 0-250 Constant (low intensity, constant
stimulation), 0-250 Cycling (low intensity, cycling stimulation), 50-250
Constant (high intensity, constant stimulation), 50-250 Cycling (high
intensity, cycling stimulation).</p>
<p>Each trajectory was simulated using the validated simulator from the
main study. The simulation incorporated population-level
gamma-difference kernel parameters, empirical turn angle and duration
distributions, run/turn state dynamics with hazard model. Track duration
was 10 minutes.</p>
<h2 id="individual-level-kernel-fitting">Individual-Level Kernel
Fitting</h2>
<p>For each simulated track, a gamma-difference kernel was fitted using
the same form as the population-level model: <span
class="math display">\[K(t) = A \cdot \text{Gamma}(t; \alpha_1, \beta_1)
- B \cdot \text{Gamma}(t; \alpha_2, \beta_2)\]</span></p>
<p>where <span class="math inline">\(\tau_1 = \alpha_1 \beta_1\)</span>
and <span class="math inline">\(\tau_2 = \alpha_2 \beta_2\)</span> are
the fast and slow timescales, respectively.</p>
<p>The kernel value <span class="math inline">\(K(t)\)</span> represents
the contribution to the log-hazard rate at time lag <span
class="math inline">\(t\)</span> after LED stimulus onset. In the hazard
model, the instantaneous event probability per frame is: <span
class="math display">\[p(t) = \exp(\beta_0 + K(t_{\text{since
onset}}))\]</span> where <span class="math inline">\(\beta_0\)</span> is
the baseline log-hazard. Positive kernel values increase event
probability, while negative values decrease it. For example, if <span
class="math inline">\(K(2.0) = +0.5\)</span> at 2 seconds after LED
onset, the event probability increases by a factor of <span
class="math inline">\(\exp(0.5) \approx 1.65\)</span> relative to
baseline. Conversely, if <span class="math inline">\(K(5.0) =
-1.0\)</span> at 5 seconds after onset, the probability decreases by a
factor of <span class="math inline">\(\exp(-1.0) \approx 0.37\)</span>,
representing suppression.</p>
<p>Kernel fitting was performed using maximum likelihood estimation
(MLE). The log-likelihood for a point process with instantaneous hazard
rate <span class="math inline">\(\lambda(t)\)</span> is: <span
class="math display">\[\log L = \sum_{i=1}^{N} \log \lambda(t_i) -
\int_0^T \lambda(t) \, dt\]</span> where <span
class="math inline">\(t_i\)</span> are the observed event times and
<span class="math inline">\(T\)</span> is the total observation
duration. The first term rewards high hazard at event times; the second
penalizes high hazard during non-event periods. In the discrete-time
Bernoulli formulation, <span class="math inline">\(\lambda(t) =
\exp(\beta_0 + K(t_{\text{since onset}}))\)</span>. The integral is
approximated by summation over frames.</p>
<p>To avoid local minima in the non-convex likelihood surface,
optimization was initialized from a grid of 18 starting points spanning
plausible parameter ranges (<span class="math inline">\(\tau_1 \in
\{0.3, 0.6, 0.9\}\)</span> s, <span class="math inline">\(\tau_2 \in
\{1.0, 2.0, 3.0\}\)</span> s, <span class="math inline">\(A/B \in \{1.0,
2.0\}\)</span>). The solution with highest log-likelihood was retained.
Optimization used L-BFGS-B with Nelder-Mead fallback for numerical
stability.</p>
<p>The parametric kernel form enables computation of event rates at any
time point without requiring data binning or extrapolation. To compute
the peri-stimulus time histogram (PSTH) from fitted kernel parameters,
the kernel function is evaluated at a fine time grid (e.g., <span
class="math inline">\(t \in [-3, 10]\)</span> seconds relative to LED
onset) and converted to event rate: <span
class="math display">\[\text{rate}(t) = \text{baseline\_rate} \times
\exp(K(t))\]</span> where baseline rate is estimated from pre-stimulus
periods. The parametric approach provides smooth, continuous rate
estimates at arbitrary temporal resolution, in contrast to empirical
PSTH methods that require binning events and may have sparse data in
some time bins.</p>
<h2 id="feature-extraction">Feature Extraction</h2>
<p>For each track, kernel parameters (<span
class="math inline">\(\tau_1\)</span>, <span
class="math inline">\(\tau_2\)</span>, <span
class="math inline">\(A\)</span>, <span
class="math inline">\(B\)</span>, <span
class="math inline">\(\alpha_1\)</span>, <span
class="math inline">\(\beta_1\)</span>, <span
class="math inline">\(\alpha_2\)</span>, <span
class="math inline">\(\beta_2\)</span>) were extracted along with
behavioral features: turn rate in turns per minute, mean turn duration
in seconds, run fraction. Fit quality was measured as <span
class="math inline">\(R^2\)</span> between the fitted kernel and
empirical PSTH.</p>
<p>Turn rate was calculated as the number of turn events (state
transitions from RUN to TURN) divided by track duration, with automatic
validation to detect inflated rates.</p>
<h2 id="clustering-analysis">Clustering Analysis</h2>
<p>Unsupervised clustering was applied to identify distinct behavioral
phenotypes using K-means clustering with Euclidean distance on
standardized features and hierarchical clustering with Ward linkage on
standardized features. The feature set included kernel parameters (<span
class="math inline">\(\tau_1\)</span>, <span
class="math inline">\(\tau_2\)</span>, <span
class="math inline">\(A\)</span>, <span
class="math inline">\(B\)</span>) alongside behavioral features (turn
rate, turn duration, run fraction). Cluster selection used silhouette
score optimization across <span class="math inline">\(k = 2\)</span> to
<span class="math inline">\(7\)</span> clusters.</p>
<h2 id="cross-validation-and-cluster-validation">Cross-Validation and
Cluster Validation</h2>
<p>Kernel fitting robustness was assessed through leave-one-track-out
cross-validation, comparing fitted parameters to original track
parameters via correlation and mean squared error. Bootstrap confidence
intervals (100 resamples) were computed for mean kernel parameters, with
track-level resampling to respect temporal autocorrelation. Clustering
stability was measured through bootstrap agreement matrices across 100
resamples. Seed sensitivity was quantified via Adjusted Rand Index
across 20 random seeds. Per-cluster silhouette scores provided
additional quality assessment.</p>
<p>Before characterizing phenotypic clusters, a three-stage validation
ensured clusters represent genuine structure rather than noise. Stage 1
tested significance via permutation: 500 null datasets were generated by
independently shuffling each feature column. Clusters were considered
significant if the observed silhouette score exceeded 95% of null
silhouettes. Stage 2 applied the gap statistic to select optimal <span
class="math inline">\(k\)</span> by comparing within-cluster dispersion
to uniform reference samples. Stage 3 assessed reproducibility using
80/20 train/test splits repeated 20 times. K-means was fitted on
training data. Test samples were assigned to nearest training centroids.
The Adjusted Rand Index between centroid-assigned labels and labels from
independent test-set clustering measured reproducibility.</p>
<div id="tab:cluster_validation">
<table>
<caption>Cluster validation criteria</caption>
<thead>
<tr>
<th style="text-align: left;">Stage</th>
<th style="text-align: left;">Test</th>
<th style="text-align: left;">Threshold</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">1</td>
<td style="text-align: left;">Permutation significance</td>
<td style="text-align: left;"><span class="math inline">\(p &lt;
0.05\)</span></td>
</tr>
<tr>
<td style="text-align: left;">2</td>
<td style="text-align: left;">Gap statistic support</td>
<td style="text-align: left;">Gap<span class="math inline">\((k)
\geq\)</span> Gap<span class="math inline">\((k+1) -
s_{k+1}\)</span></td>
</tr>
<tr>
<td style="text-align: left;">3</td>
<td style="text-align: left;">Train/test reproducibility</td>
<td style="text-align: left;">ARI <span class="math inline">\(&gt;
0.5\)</span></td>
</tr>
</tbody>
</table>
</div>
<h2 id="empirical-data-quality-control">Empirical Data Quality
Control</h2>
<h3 id="track-segmentation-validation">Track Segmentation
Validation</h3>
<p>Empirical larval trajectories undergo MAGAT segmentation to identify
behavioral states (runs, reorientations, head swings) and generate the
Klein run table, a canonical record of all run segments and their
associated reorientation events. The segmentation step is required for
kernel fitting because it defines the reorientation onset events used as
the dependent variable.</p>
<p>A critical data quality issue was identified: of 701 unique
(experiment, track) pairs in the consolidated dataset, only 424 (60.5%)
successfully passed MAGAT segmentation. The remaining 277 tracks (39.5%)
have zero reorientation events in the events table and no entries in the
Klein run table, indicating complete segmentation failure rather than
biological low-activity phenotypes.</p>
<h3 id="track-selection-criteria">Track Selection Criteria</h3>
<p>Tracks were filtered hierarchically for phenotyping analysis. First,
duration was required to be at least 10 minutes to ensure sufficient
LED-ON cycles for kernel estimation. Second, presence in the Klein run
table confirmed successful MAGAT segmentation. Third, at least 10
reorientation events were required for adequate statistical power. After
filtering, 260 tracks remained for analysis (Table <a
href="#tab:track_filtering" data-reference-type="ref"
data-reference="tab:track_filtering">2</a>).</p>
<div id="tab:track_filtering">
<table>
<caption>Track filtering pipeline for empirical phenotyping
analysis</caption>
<thead>
<tr>
<th style="text-align: left;"><strong>Filter Stage</strong></th>
<th style="text-align: right;"><strong>Tracks</strong></th>
<th style="text-align: right;"><strong>Mean Events/Track</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">All tracks (consolidated dataset)</td>
<td style="text-align: right;">701</td>
<td style="text-align: right;">11.2</td>
</tr>
<tr>
<td style="text-align: left;">With Klein run table entry</td>
<td style="text-align: right;">424</td>
<td style="text-align: right;">18.6</td>
</tr>
<tr>
<td style="text-align: left;">Without Klein entry (excluded)</td>
<td style="text-align: right;">277</td>
<td style="text-align: right;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">Duration <span
class="math inline">\(\geq\)</span> 10 min</td>
<td style="text-align: right;">349</td>
<td style="text-align: right;">—</td>
</tr>
<tr>
<td style="text-align: left;">With Klein data</td>
<td style="text-align: right;">299</td>
<td style="text-align: right;">22.7</td>
</tr>
<tr>
<td style="text-align: left;">Without Klein data (excluded)</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">0.0</td>
</tr>
<tr>
<td style="text-align: left;">Events <span
class="math inline">\(\geq\)</span> 10 (final)</td>
<td style="text-align: right;"><strong>260</strong></td>
<td style="text-align: right;"><strong>25.2</strong></td>
</tr>
</tbody>
</table>
</div>
<h3 id="kernel-fitting-success-criteria">Kernel Fitting Success
Criteria</h3>
<p>Individual-level kernel fitting was considered successful when
L-BFGS-B optimization converged within parameter bounds. The fitted
kernel was required to exhibit expected gamma-difference characteristics
with a fast excitatory peak followed by slow suppressive trough. Time
constants were required to remain physiologically plausible with <span
class="math inline">\(\tau_1\)</span> between 0.1 and 3.0 seconds and
<span class="math inline">\(\tau_2\)</span> between 1.0 and 10.0
seconds. Parameter bounds were set based on population-level estimates:
amplitude <span class="math inline">\(A\)</span> in [0.1, 5.0], fast
shape <span class="math inline">\(\alpha_1\)</span> in [1.0, 5.0], fast
scale <span class="math inline">\(\beta_1\)</span> in [0.05, 1.0]
seconds, suppression amplitude <span class="math inline">\(B\)</span> in
[5.0, 20.0], slow shape <span class="math inline">\(\alpha_2\)</span> in
[2.0, 8.0], slow scale <span class="math inline">\(\beta_2\)</span> in
[0.3, 2.0] seconds.</p>
<h2 id="comparison-of-simulated-vs.-empirical-data">Comparison of
Simulated vs. Empirical Data</h2>
<p>Parallel analyses were performed on simulated (300 tracks, 20-minute
duration) and empirical (260 tracks, 10-20 minute duration) datasets.
Simulated tracks generated from the population-level hazard model showed
145-338 events per track, while empirical tracks showed 10-79 events per
track, reflecting differences in discrete-time Bernoulli sampling.
Simulated tracks used population-level kernel parameters with only
track-specific random intercepts (<span class="math inline">\(\sigma =
0.47\)</span>), while empirical tracks may exhibit genuine kernel
parameter variation. Simulated data was expected to show minimal
phenotypic clustering, while empirical data might reveal distinct
behavioral phenotypes not captured by the random-intercept model.</p>
<h2 id="psth-and-kernel-relationship">PSTH and Kernel Relationship</h2>
<p>Figure <a href="#fig:psth_kernel" data-reference-type="ref"
data-reference="fig:psth_kernel">1</a> illustrates the relationship
between the peri-stimulus time histogram (PSTH), the gamma-difference
kernel <span class="math inline">\(K(t)\)</span>, and the Bernoulli
event generation process.</p>
<figure id="fig:psth_kernel">
<embed src="fig3_psth_kernel_v2.png" />
<figcaption><strong>From empirical PSTH to generative model.</strong>
<strong>(A)</strong> Empirical peri-stimulus time histogram (PSTH)
showing reorientation event rate aligned to LED onset (t=0). Events are
binned in 0.5-second intervals. The biphasic response shows early
excitation (peak at <span class="math inline">\(\sim\)</span>2s)
followed by suppression (trough at <span
class="math inline">\(\sim\)</span>5s). <strong>(B)</strong> Fitted
gamma-difference kernel <span class="math inline">\(K(t) = A \cdot
\Gamma(t; \alpha_1, \beta_1) - B \cdot \Gamma(t; \alpha_2,
\beta_2)\)</span>. Positive values indicate increased event probability;
negative values indicate suppression relative to baseline.
<strong>(C)</strong> Per-frame event probability <span
class="math inline">\(p(t) = \exp(\beta_0 + K(t))\)</span>, where <span
class="math inline">\(\beta_0\)</span> is the baseline log-hazard. The
kernel modulates this probability around the <span
class="math inline">\(\sim\)</span>2% baseline rate.
<strong>(D)</strong> Discrete-time Bernoulli process: at each 50ms
frame, a random draw determines whether an event occurs based on <span
class="math inline">\(p(t)\)</span>. The generative process can simulate
synthetic tracks matching empirical statistics.</figcaption>
</figure>
<p>The parametric kernel <span class="math inline">\(K(t)\)</span>
provides a mechanistic explanation for the empirical PSTH shape: fast
excitation (<span class="math inline">\(\tau_1 \approx 0.3\)</span>s)
drives the initial peak, while slow suppression (<span
class="math inline">\(\tau_2 \approx 4\)</span>s) creates the subsequent
trough. The gamma-difference form enables both prediction (evaluating
<span class="math inline">\(K(t)\)</span> at arbitrary time points) and
simulation (generating synthetic events via Bernoulli sampling).</p>
<h2 id="psth-construction-and-optimal-bin-width">PSTH Construction and
Optimal Bin Width</h2>
<p>The peri-stimulus time histogram (PSTH) visualizes event rates
relative to stimulus onset. Construction involves aligning all event
sequences to LED activation at <span class="math inline">\(t=0\)</span>.
The observation window is divided into bins of width <span
class="math inline">\(\Delta\)</span>. Events are counted per bin across
all stimulus presentations. Counts are normalized by trial count and bin
width to obtain rate in events per second.</p>
<p>Bin width critically affects PSTH quality: too narrow yields noisy
estimates, too wide obscures temporal structure. Following Shimazaki and
Shinomoto, the optimal bin width <span
class="math inline">\(\Delta^*\)</span> minimizes the cost function
<span class="math inline">\(C(\Delta) = (2\bar{k} -
v)/\Delta^2\)</span>, where <span class="math inline">\(\bar{k}\)</span>
is mean event count per bin and <span class="math inline">\(v\)</span>
is variance across bins. The derivation assumes events are generated by
an inhomogeneous Poisson process. The PSTH must be an unbiased
estimator. Bin counts must be approximately independent. For the present
data, optimal bin widths of 0.4-0.6 seconds were computed.</p>
<p>The parametric gamma-difference kernel <span
class="math inline">\(K(t)\)</span> provides an alternative that avoids
the bias-variance tradeoff. The continuous rate estimate <span
class="math inline">\(\hat{\lambda}(t) = \lambda_0 \cdot
\exp(K(t))\)</span> enables rate estimation at arbitrary temporal
resolution. Statistical strength is shared across time points via the
parametric form. Fewer parameters are required than typical PSTH
representations. The tradeoff is that parametric fitting requires
sufficient data for reliable estimation, while PSTH construction works
with any event count.</p>
<h2 id="fourier-neural-operator-for-kernel-recovery">Fourier Neural
Operator for Kernel Recovery</h2>
<p>Given the failure of parametric fitting to recover individual kernel
parameters, a neural operator approach was explored that learns the
mapping from event patterns to kernel shapes end-to-end. A 1D Fourier
Neural Operator (FNO) takes a normalized PSTH vector (20 bins, 0-10s
post-LED onset) as input. A lifting layer projects to 64 hidden
dimensions. Four FNO layers apply spectral convolution in Fourier space
with 8 retained modes plus pointwise convolution and GELU activation.
The final layer projects to kernel values on a 60-point grid. The
spectral convolution operates as <span
class="math inline">\((\mathcal{K}v)(x) = \mathcal{F}^{-1}(R \cdot
\mathcal{F}(v))(x)\)</span> where <span class="math inline">\(R\)</span>
is a learned weight tensor.</p>
<p>Training data comprised 2000 synthetic tracks with kernel parameters
sampled uniformly (<span class="math inline">\(\tau_1 \in [0.1,
1.0]\)</span>, <span class="math inline">\(\tau_2 \in [2.0,
8.0]\)</span>, <span class="math inline">\(A \in [0.5, 3.0]\)</span>,
<span class="math inline">\(B \in [5.0, 25.0]\)</span>). Events were
simulated via discrete-time Bernoulli process. PSTH was computed from
simulated events. The model was trained to minimize MSE between
predicted and true kernel curves using Adam optimizer with
ReduceLROnPlateau scheduler for 100 epochs. Neural operators offer
advantages over parametric fitting. Parameters are regularized by joint
training across all tracks. The model learns kernel shape without
assuming gamma-difference form. Deep learning naturally handles noisy
inputs.</p>
<h2 id="hierarchical-bayesian-model">Hierarchical Bayesian Model</h2>
<p>Given the limitations of independent track-level fitting, a
hierarchical Bayesian model jointly estimates population and individual
parameters. When MLE is applied independently to each track, sparse data
(20 events for 6 parameters) produces extreme estimates: <span
class="math inline">\(\tau_1\)</span> values ranging from 0.1s to 5s
even when all larvae share similar true parameters. Hierarchical
modeling addresses this by estimating population-level means (<span
class="math inline">\(\mu_{\tau_1}\)</span>, <span
class="math inline">\(\mu_{\tau_2}\)</span>) and variances (<span
class="math inline">\(\sigma_{\tau_1}\)</span>, <span
class="math inline">\(\sigma_{\tau_2}\)</span>) simultaneously with
individual parameters. Individual <span
class="math inline">\(\tau_1\)</span> estimates are then pulled toward
<span class="math inline">\(\mu_{\tau_1}\)</span> in proportion to their
uncertainty. A track with 5 events is pulled strongly toward the
population mean; a track with 50 events retains more of its individual
signal. The resulting posterior distributions for each individual
include credible intervals that account for both measurement uncertainty
and population variability.</p>
<p>At the population level, hyperpriors specify: <span
class="math display">\[\begin{aligned}
\mu_{\tau_1} &amp;\sim \text{Normal}(\log(0.3), 0.5) \notag \\
\mu_{\tau_2} &amp;\sim \text{Normal}(\log(4.0), 0.5) \notag \\
\sigma_{\tau_1}, \sigma_{\tau_2} &amp;\sim \text{HalfNormal}(0.3) \notag
\end{aligned}\]</span></p>
<p>At the individual level, partial pooling specifies <span
class="math inline">\(\tau_{1,i} \sim \text{LogNormal}(\mu_{\tau_1},
\sigma_{\tau_1})\)</span> and <span class="math inline">\(\tau_{2,i}
\sim \text{LogNormal}(\mu_{\tau_2}, \sigma_{\tau_2})\)</span>. The
likelihood is: <span class="math display">\[\text{PSTH}_i(t) \sim
\text{Normal}(\exp(\beta_0 + K(t; \tau_{1,i}, \tau_{2,i}, A_i, B_i)),
\sigma_{\text{obs}}) \notag\]</span></p>
<p>The model has three key properties. Tracks with sparse data are
pulled toward the population mean, preventing overfitting. Each
individual’s parameters have posterior distributions with credible
intervals, allowing identification of tracks that genuinely differ from
population. Information from all 256 tracks informs the population
parameters, which in turn regularize each individual estimate.</p>
<p>Inference used the No-U-Turn Sampler (NUTS) in NumPyro with 500
warmup iterations and 1000 sampling iterations across 2 independent
chains. Convergence was assessed via <span
class="math inline">\(\hat{R}\)</span> statistics and effective sample
size.</p>
<h2 id="sec:power_analysis">Power Analysis</h2>
<p>Power analysis answers a fundamental question: <em>How much data do
we need to reliably detect a real difference?</em> This section explains
the concepts and methodology.</p>
<h3 id="two-types-of-errors">Two Types of Errors</h3>
<p>When claiming that an individual larva differs from the population,
two types of mistakes are possible:</p>
<h4 id="type-i-error-false-positive.">Type I error (false
positive).</h4>
<p>Claiming a larva is “different” when it is actually typical. For
example: a larva with true <span class="math inline">\(\tau_1 =
0.63\)</span> s (population average) happens to produce an unusual
pattern of events by chance. The method incorrectly flags it as a fast
responder.</p>
<p>The Type I error rate should be controlled at a pre-specified level,
conventionally 5%. Among larvae that are truly typical, at most 5%
should be wrongly flagged as different.</p>
<h4 id="type-ii-error-false-negative.">Type II error (false
negative).</h4>
<p>Failing to detect a larva that is genuinely different. For example: a
true fast responder with <span class="math inline">\(\tau_1 =
0.43\)</span> s produces events that happen to look average, and the
method misses it.</p>
<p><strong>Power</strong> is defined as <span class="math inline">\(1 -
\text{Type II error rate}\)</span>, i.e., the probability of correctly
detecting a true difference. A power of 80% means: among larvae that are
genuinely fast responders, we correctly identify 80% of them.</p>
<h3 id="why-this-matters-for-phenotyping">Why This Matters for
Phenotyping</h3>
<p>If power is low, then even if fast responders exist, we will miss
most of them. An observed 8% could represent a genuine 8% subpopulation
if power is high, a small fraction of a much larger subpopulation if
power is low, or entirely false positives if Type I error is not
controlled. Power analysis determines which interpretation is
plausible.</p>
<h3 id="simulation-based-power-calculation">Simulation-Based Power
Calculation</h3>
<p>Since analytical power formulas do not exist for this nonlinear
hierarchical model, power was computed by simulation. The effect size
was defined as <span class="math inline">\(\Delta\tau_1 =
0.2\)</span> s, comparing population (<span class="math inline">\(\tau_1
= 0.63\)</span> s) to fast responder (<span class="math inline">\(\tau_1
= 0.43\)</span> s). For each target event count from 25 to 200, 100
tracks were simulated from each kernel type. Tracks were fitted via MLE.
95% confidence intervals for <span class="math inline">\(\tau_1\)</span>
were computed via parametric bootstrap. Type I error was computed as the
proportion of population tracks whose CI incorrectly excluded 0.63 s,
which should be approximately 5%. Power was computed as the proportion
of fast-responder tracks whose CI correctly excluded 0.63 s, which
should increase with event count.</p>
<h3 id="technical-details">Technical Details</h3>
<p>Three methodological choices are critical for reliable power
estimation. Confidence intervals were computed via parametric bootstrap
because standard resampling fails for point processes: events are not
exchangeable, resampling destroys temporal structure, resulting CIs
would be overconfident. Parametric bootstrap solves this by fitting the
model to observed data to obtain MLE parameters. New event trains are
simulated from the fitted model using the same stimulus protocol. The
model is re-fitted to each simulated track. The 95% CI is computed as
the 2.5th to 97.5th percentile across 200 bootstrap samples. If a
larva’s CI excludes the population mean, response timing differs
significantly from average; the width of the CI determines ability to
detect differences.</p>
<p>The point-process log-likelihood includes both event contributions
and a penalty for time without events: <span class="math display">\[\log
L = \sum_{i=1}^{N} \log \lambda(t_i) - \int_0^T \lambda(t) \, dt
\label{eq:loglik_integral}\]</span> where <span
class="math inline">\(\lambda(t)\)</span> is instantaneous hazard and
<span class="math inline">\(T\)</span> is track duration. Omitting the
integral term would bias estimates toward unrealistically high hazard
rates.</p>
<p>The 6-parameter kernel produces a non-convex likelihood surface, so
MLE was initialized from 18 grid points spanning <span
class="math inline">\(\tau_1 \in \{0.3, 0.6, 0.9\}\)</span> s, <span
class="math inline">\(\tau_2 \in \{1.0, 2.0, 3.0\}\)</span> s, and <span
class="math inline">\(A/B \in \{1.0, 2.0\}\)</span>. The optimization
with highest log-likelihood was retained. Without multi-start
initialization, approximately 15–20% of tracks converged to local
minima. Additional implementation details including GPU vectorization
are documented in the code repository.</p>
<h3 id="interpreting-the-results">Interpreting the Results</h3>
<p>If the analysis is well-calibrated, Type I error should remain
approximately 5% regardless of event count since the threshold is set to
achieve this. Power should increase as event count increases. The key
output is the event count required to achieve 80% power. If this value
exceeds the typical 18–25 events in the data, the data are under-powered
for individual-level phenotyping.</p>
<h2 id="sec:ppc">Posterior Predictive Checks</h2>
<p>Posterior predictive checks (PPC) were performed to validate the
hierarchical Bayesian model. For each of 256 tracks, 100 posterior
samples of <span class="math inline">\((\tau_1, \tau_2)\)</span> were
drawn. For each sample, a synthetic event train was simulated using the
Bernoulli process. Summary statistics were computed for each simulation:
event count, mean inter-stimulus interval (ISI), ISI variance, PSTH
correlation with observed data.</p>
<p>The model was considered adequate if <span
class="math inline">\(\geq\)</span>90% of tracks had observed statistics
falling within the 95% posterior predictive interval for at least two of
three metrics.</p>
<h2 id="sec:model_selection">Model Selection</h2>
<p>Model comparison was performed between the full 6-parameter model (A,
<span class="math inline">\(\alpha_1\)</span>, <span
class="math inline">\(\beta_1\)</span>, B, <span
class="math inline">\(\alpha_2\)</span>, <span
class="math inline">\(\beta_2\)</span> estimated per track) and a
reduced 2-parameter model (<span class="math inline">\(\tau_1\)</span>,
<span class="math inline">\(\tau_2\)</span> estimated per track; A, B
fixed at population values). Both models were fitted via MLE to all
tracks. The Bayesian Information Criterion (BIC) and Akaike Information
Criterion (AIC) were computed: <span
class="math display">\[\begin{aligned}
\text{BIC} &amp;= k \ln(n) - 2 \ln(\hat{L}) \\
\text{AIC} &amp;= 2k - 2 \ln(\hat{L})
\end{aligned}\]</span> where <span class="math inline">\(k\)</span> is
the number of parameters, <span class="math inline">\(n\)</span> is the
number of events, and <span class="math inline">\(\hat{L}\)</span> is
the maximum likelihood.</p>
<p>The model with lower total BIC across tracks was preferred.</p>
<h2 id="sec:loeo">Leave-One-Experiment-Out Cross-Validation</h2>
<p>To assess generalization across experiments, leave-one-experiment-out
cross-validation (LOEO-CV) was performed. For each of 14 experiments,
the population-level kernel was estimated from the remaining 13
experiments. The predictive log-likelihood was computed for the held-out
experiment. The coefficient of variation (CV) of population <span
class="math inline">\(\tau_1\)</span> across folds quantified parameter
stability: <span class="math display">\[\text{CV} =
\frac{\sigma_{\tau_1}}{\mu_{\tau_1}} \times 100\%\]</span></p>
<p>CV <span class="math inline">\(&lt;\)</span>10% indicates stable
population estimates; CV <span class="math inline">\(&gt;\)</span>20%
indicates significant experiment-specific effects.</p>
<h2 id="statistical-analysis">Statistical Analysis</h2>
<p>All analyses were performed in Python 3.14. Kernel fitting used
<code>scipy.optimize</code>. Clustering used <code>scikit-learn</code>.
Data manipulation used <code>pandas</code> and <code>numpy</code>.
Custom validation functions handled turn rate detection.</p>
<h1 id="results">Results</h1>
<h2 id="tracks-meet-quality-criteria">260 Tracks Meet Quality
Criteria</h2>
<p>From the consolidated experimental dataset of 701 unique larval
tracks across 14 experiments, 424 tracks (60.5%) were identified with
successful MAGAT behavioral segmentation. The remaining 277 tracks had
zero detected reorientation events, indicating segmentation failure
rather than biological inactivity.</p>
<p>After applying duration (<span class="math inline">\(\geq\)</span>10
min) and event count (<span class="math inline">\(\geq\)</span>10
events) thresholds, 260 tracks remained for individual-level phenotyping
analysis. The tracks averaged 25.2 reorientation events per track
(range: 10–79), with mean duration of 16.3 minutes. The full Klein run
table contains 8,822 reorientation events across 424 tracks (mean: 20.8
events/track, median: 18.0).</p>
<h4 id="statistical-constraint.">Statistical constraint.</h4>
<p>The 6-parameter gamma-difference kernel fitted to tracks with median
18 events yields a data-to-parameter ratio of 3:1. Individual-level
parameter estimates are therefore expected to be unstable and heavily
influenced by prior assumptions or regularization.</p>
<h2
id="individual-kernels-fit-successfully-with-high-apparent-separation">Individual
Kernels Fit Successfully with High Apparent Separation</h2>
<p>Kernel fitting succeeded for all 260 empirical tracks meeting the
quality criteria. For comparison, 300 simulated 20-minute tracks were
analyzed, generated from population-level parameters with track-specific
random intercepts. Simulated tracks showed 145–338 events per track
(mean: 252), and kernel fitting succeeded for all simulated tracks with
mean parameter recovery within 5% of ground truth values.</p>
<h3 id="four-clusters-emerge-with-99.6-classification-accuracy">Four
Clusters Emerge with 99.6% Classification Accuracy</h3>
<p>Linear discriminant analysis achieved 99.6% classification accuracy
(10-fold CV), confirming that the four clusters are clearly separable in
kernel parameter space. Table <a href="#tab:centroids"
data-reference-type="ref" data-reference="tab:centroids">3</a> shows
cluster centroids.</p>
<div id="tab:centroids">
<table>
<caption>Cluster centroids (k=4) showing mean kernel parameters per
phenotype</caption>
<thead>
<tr>
<th style="text-align: left;"><strong>Cluster</strong></th>
<th style="text-align: center;"><strong>N (%)</strong></th>
<th style="text-align: center;"><strong><span
class="math inline">\(\tau_1\)</span> (s)</strong></th>
<th style="text-align: center;"><strong><span
class="math inline">\(\tau_2\)</span> (s)</strong></th>
<th style="text-align: center;"><strong>A</strong></th>
<th style="text-align: center;"><strong>B</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">0: Standard</td>
<td style="text-align: center;">128 (49%)</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">6.6</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">19.9</td>
</tr>
<tr>
<td style="text-align: left;">1: Inverted timescales</td>
<td style="text-align: center;">11 (4%)</td>
<td style="text-align: center;"><strong>5.0</strong></td>
<td style="text-align: center;"><strong>0.63</strong></td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">20.0</td>
</tr>
<tr>
<td style="text-align: left;">2: Strong excitation</td>
<td style="text-align: center;">115 (44%)</td>
<td style="text-align: center;">0.22</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;"><strong>5.0</strong></td>
<td style="text-align: center;">20.0</td>
</tr>
<tr>
<td style="text-align: left;">3: Weak suppression</td>
<td style="text-align: center;">6 (2%)</td>
<td style="text-align: center;">0.18</td>
<td style="text-align: center;">10.8</td>
<td style="text-align: center;">4.2</td>
<td style="text-align: center;"><strong>12.2</strong></td>
</tr>
</tbody>
</table>
</div>
<p>All four kernel parameters differed significantly across clusters
(Kruskal-Wallis, all <span class="math inline">\(p &lt; 0.001\)</span>)
with large effect sizes: <span class="math inline">\(\tau_1\)</span>
(<span class="math inline">\(\eta^2 = 0.97\)</span>), <span
class="math inline">\(A\)</span> (<span class="math inline">\(\eta^2 =
0.97\)</span>), <span class="math inline">\(B\)</span> (<span
class="math inline">\(\eta^2 = 0.81\)</span>), and <span
class="math inline">\(\tau_2\)</span> (<span
class="math inline">\(\eta^2 = 0.17\)</span>). Detailed clustering
stability analysis is provided in Appendix <a href="#app:clustering"
data-reference-type="ref" data-reference="app:clustering">6</a>.</p>
<h2
id="round-trip-validation-reveals-phenotypes-are-not-recoverable">Round-Trip
Validation Reveals Phenotypes Are Not Recoverable</h2>
<p>Round-trip validation tested whether identified phenotypes represent
recoverable individual differences. Synthetic tracks were generated from
phenotype-specific kernel parameters, kernels were fitted to the
synthetic data, and cluster assignments were compared to ground
truth.</p>
<p>The validation failed: cluster recovery ARI was 0.128 (expected <span
class="math inline">\(&gt;\)</span>0.5), and parameter correlations were
near zero or negative (<span class="math inline">\(\tau_1\)</span>:
<span class="math inline">\(r = -0.03\)</span>; <span
class="math inline">\(\tau_2\)</span>: <span class="math inline">\(r =
-0.62\)</span>). The near-zero correlations indicate that kernel fitting
from sparse event data (<span class="math inline">\(\sim\)</span>25
events/track) cannot reliably recover ground-truth parameters. Full
protocol details are provided in Appendix <a href="#app:roundtrip"
data-reference-type="ref" data-reference="app:roundtrip">8</a>.</p>
<h2
id="hierarchical-bayesian-model-reveals-population-homogeneity">Hierarchical
Bayesian Model Reveals Population Homogeneity</h2>
<p>A hierarchical Bayesian model was fit to jointly estimate population
and individual parameters, properly accounting for uncertainty and
regularizing sparse tracks.</p>
<h3 id="population-tau_1-0.63s-slower-than-original-estimate">Population
<span class="math inline">\(\tau_1 = 0.63\)</span>s, Slower Than
Original Estimate</h3>
<p>The hierarchical model estimated population-level kernel parameters:
<span class="math inline">\(\tau_1 = 0.63\)</span> s (fast excitation
timescale), <span class="math inline">\(\tau_2 = 2.48\)</span> s (slow
suppression timescale), with individual variation <span
class="math inline">\(\sigma_{\tau_1} = 0.31\)</span> and <span
class="math inline">\(\sigma_{\tau_2} = 0.46\)</span>.</p>
<h3 id="of-tracks-are-genuine-outliers">8.6% of Tracks Are Genuine
Outliers</h3>
<p>The hierarchical model identifies individuals whose 95% credible
intervals do not overlap with the population mean. Of 256 tracks, 22
(8.6%) were identified as <span class="math inline">\(\tau_1\)</span>
outliers, and 16 (6.2%) as <span class="math inline">\(\tau_2\)</span>
outliers. Clustering on hierarchical Bayesian posterior means showed no
agreement with MLE-based clusters (ARI <span
class="math inline">\(\approx\)</span> 0).</p>
<figure id="fig:summary">
<embed src="core/fig_combined_summary.png" />
<figcaption><strong>Validation results and hierarchical
shrinkage.</strong> <strong>(A)</strong> PCA of kernel parameters shows
a unimodal distribution with scattered outliers, not discrete clusters.
Points are colored by density, not cluster assignment.
<strong>(B)</strong> All validation methods failed: round-trip
clustering (ARI = 0.13), PSTH vs kernel agreement (ARI = 0.01), FNO vs
parametric (ARI = 0.01), and Bayesian vs MLE (ARI <span
class="math inline">\(\approx\)</span> 0). Green dashed line indicates
success threshold (ARI = 0.5). <strong>(C)</strong> Caterpillar plot of
individual <span class="math inline">\(\tau_1\)</span> posterior
distributions sorted by mean. Orange intervals indicate the 8.6% of
tracks whose 95% CIs exclude the population mean (red vertical line at
0.63s). Gray intervals show the 91% of tracks consistent with the
population. <strong>(D)</strong> Violin comparison of <span
class="math inline">\(\tau_1\)</span> posteriors for normal (n=234) vs
outlier (n=22) tracks. Outliers cluster at lower <span
class="math inline">\(\tau_1\)</span> (<span
class="math inline">\(\approx\)</span>0.45s), suggesting faster response
dynamics. Dashed line indicates population mean.</figcaption>
</figure>
<p>The validation failures and hierarchical shrinkage shown in Figure <a
href="#fig:summary" data-reference-type="ref"
data-reference="fig:summary">2</a> demonstrate that apparent phenotypic
clusters are artifacts of sparse data rather than genuine individual
differences. The hierarchical Bayesian model reveals that most tracks
are consistent with the population mean, with only 8.6% identified as
genuine outliers.</p>
<figure id="fig:shrinkage">
<embed src="core/fig3_hierarchical_shrinkage.png" />
<figcaption><strong>Hierarchical Bayesian modeling reveals population
homogeneity.</strong> <strong>(A)</strong> Caterpillar plot showing 95%
credible intervals for <span class="math inline">\(\tau_1\)</span> for
all 256 tracks, sorted by posterior mean. Orange intervals (22 tracks,
8.6%) have CIs that exclude the population mean; gray intervals (234
tracks, 91.4%) are consistent with the population. The vertical red line
marks the population mean (<span class="math inline">\(\tau_1 =
0.63\)</span>s). <strong>(B)</strong> MLE vs Bayesian <span
class="math inline">\(\tau_1\)</span> estimates. Extreme MLE values (up
to 5s) are shrunk toward the population mean (<span
class="math inline">\(\approx\)</span>0.65s) by the hierarchical
prior.</figcaption>
</figure>
<p>Figure <a href="#fig:shrinkage" data-reference-type="ref"
data-reference="fig:shrinkage">3</a> shows how hierarchical Bayesian
estimation shrinks extreme MLE estimates toward the population mean. The
22 outlier tracks identified by the hierarchical model represent
candidate fast responders (Figure <a href="#fig:fast_responders"
data-reference-type="ref"
data-reference="fig:fast_responders">4</a>).</p>
<figure id="fig:fast_responders">
<embed src="core/fig4_fast_responders.png" />
<figcaption><strong>Candidate fast responders.</strong>
<strong>(A)</strong> Violin plot comparing <span
class="math inline">\(\tau_1\)</span> distributions for normal (n=234)
vs outlier (n=22) tracks. Outliers show systematically lower <span
class="math inline">\(\tau_1\)</span> (median <span
class="math inline">\(\approx\)</span>0.45s) compared to normal tracks
(median <span class="math inline">\(\approx\)</span>0.70s).
<strong>(B)</strong> Kernel shape comparison. The population kernel
(blue, <span class="math inline">\(\tau_1 = 0.63\)</span>s) and
hypothetical fast-responder kernel (orange dashed, <span
class="math inline">\(\tau_1 = 0.45\)</span>s) show the expected
difference in peak response time. With only 22 candidate tracks and no
independent validation, the candidates require confirmation in a
separate experiment.</figcaption>
</figure>
<h2 id="current-data-achieves-only-2030-power">Current Data Achieves
Only 20–30% Power</h2>
<p>Simulation-based power analysis determined how many events per larva
are needed to reliably detect a fast responder. Power increased
monotonically with the number of events per track: at <span
class="math inline">\(N = 25\)</span> events (current data), power was
approximately 20–30%; at <span class="math inline">\(N = 100\)</span>
events, power reached 75–85%. Type I error remained controlled near the
nominal 5% level across all event counts tested.</p>
<p>With only <span class="math inline">\(\sim\)</span>18–25 events per
track and power of 20–30%, at most one-third of true fast responders can
be detected. To achieve 80% power for detecting a <span
class="math inline">\(\Delta\tau_1 = 0.2\)</span> s difference,
approximately 100 events per track are required, roughly 4<span
class="math inline">\(\times\)</span> more than typical 20-minute
recordings provide. Detailed power analysis results are provided in
Appendix <a href="#app:enhancements" data-reference-type="ref"
data-reference="app:enhancements">10</a>.</p>
<p>The identifiability problem is not simply about event count;
information content per event matters equally. Burst stimulation yields
substantially higher Fisher Information for <span
class="math inline">\(\tau_1\)</span> compared to continuous stimulation
(Figure <a href="#fig:identifiability" data-reference-type="ref"
data-reference="fig:identifiability">5</a>). The mechanism relates to
information localization: the excitatory component peaks early after LED
onset and carries nearly all <span class="math inline">\(\tau_1\)</span>
information. Continuous stimulation samples this early window once per
cycle; burst stimulation samples it multiple times.</p>
<figure id="fig:identifiability">
<embed src="fig2_identifiability_v3.png" />
<figcaption><strong>The identifiability problem and design
optimization.</strong> <strong>(A)</strong> Bias and RMSE for <span
class="math inline">\(\tau_1\)</span> estimation across four stimulus
designs at current event counts (<span
class="math inline">\(\sim\)</span>17 events). Burst design (10<span
class="math inline">\(\times\)</span>0.5s pulses) achieves bias of 0.14s
and RMSE of 0.38s, compared to continuous design with bias <span
class="math inline">\(&gt;\)</span>0.6s and RMSE <span
class="math inline">\(&gt;\)</span>0.7s. <strong>(B)</strong> Fisher
Information for <span class="math inline">\(\tau_1\)</span> across
designs. Burst design provides 10<span
class="math inline">\(\times\)</span> higher information per unit ON
time than continuous stimulation. <strong>(C)</strong> MLE parameter
recovery showing systematic positive bias with continuous stimulation.
<strong>(D)</strong> The inhibition-dominated kernel (B/A <span
class="math inline">\(\approx\)</span> 8) concentrates <span
class="math inline">\(\tau_1\)</span> information in the early
excitatory phase (0–0.3s post-onset), which burst designs sample
repeatedly.</figcaption>
</figure>
<h2 id="optimal-design-depends-on-kernel-regime">Optimal Design Depends
on Kernel Regime</h2>
<p>The systematic sweep across six A/B ratios from 0.125 to 4.0 and four
stimulation designs reveals that optimal protocol depends on kernel
regime (Figure <a href="#fig:design_comparison"
data-reference-type="ref"
data-reference="fig:design_comparison">6</a>).</p>
<figure id="fig:design_comparison">
<embed src="fig_design_comparison_summary.png" />
<figcaption><strong>Design recommendations depend on kernel
regime.</strong> <strong>(A)</strong> Fisher Information for <span
class="math inline">\(\tau_1\)</span> across four stimulation designs
and six kernel regimes (A/B = 0.125 to 4.0). Burst design provides
highest information for inhibitory kernels (A/B <span
class="math inline">\(\leq\)</span> 0.25); continuous design is
sufficient for excitatory kernels. <strong>(B)</strong> Statistical
power to detect a 0.2s difference in <span
class="math inline">\(\tau_1\)</span>. At A/B = 0.125, only burst
achieves 100% power; at A/B <span class="math inline">\(\geq\)</span>
0.25, all designs succeed. <strong>(C)</strong> Estimation bias by
regime. Burst reduces bias from 0.6s to 0.14s for inhibitory kernels.
For A/B <span class="math inline">\(\geq\)</span> 1.0, all designs show
persistent bias of approximately 0.65s. <strong>(D)</strong> Event
counts increase dramatically with A/B ratio: 17 events at A/B = 0.125 vs
228–4815 events at A/B <span class="math inline">\(\geq\)</span>
0.5.</figcaption>
</figure>
<p>Figure <a href="#fig:stimulation_schematic" data-reference-type="ref"
data-reference="fig:stimulation_schematic">7</a> illustrates the four
stimulation designs compared.</p>
<p>For inhibitory-dominated kernels with A/B at or below 0.25, burst
stimulation is optimal. At the current experimental parameters (A/B =
0.125), burst achieves bias of 0.14s and RMSE of 0.38s with
approximately 17 events, compared to bias greater than 0.6s for
continuous stimulation. Fisher Information is 10-fold higher for
burst.</p>
<p>For balanced kernels with A/B near 0.25, all pulsed designs achieve
near-perfect estimation. Bias drops below 0.02s and event counts
increase to approximately 46 per track.</p>
<p>For excitatory-dominated kernels with A/B at or above 0.5, continuous
stimulation becomes optimal. Event counts increase dramatically to
228–735 events per track because the excitatory component drives rather
than suppresses events. All designs achieve full power, but continuous
is simpler to implement.</p>
<p>At very high A/B ratios of 1.0 or above, all designs show persistent
bias of approximately 0.65s regardless of event count. The pattern
suggests a different identifiability limitation, possibly related to
parameter grid boundaries or model misspecification for
excitatory-dominated responses.</p>
<p>The practical recommendation for current data (A/B approximately
0.125): use burst stimulation with 10 pulses of 0.5s ON and 0.5s gaps to
achieve reliable <span class="math inline">\(\tau_1\)</span> estimation
without extending recording duration.</p>
<figure id="fig:stimulation_schematic">
<embed src="fig_stimulation_schematic.png" />
<figcaption><strong>Comparison of LED stimulation designs within a
30-second cycle.</strong> <strong>(A)</strong> Current design: 10s
continuous ON followed by 20s OFF. Low power and high bias result from
spending most time in the inhibitory regime. <strong>(B)</strong>
Recommended burst design: 10 pulses of 0.5s ON with 0.5s gaps. Achieves
8<span class="math inline">\(\times\)</span> more informative events by
repeatedly sampling the excitatory onset. <strong>(C)</strong> Medium
pulse design: 4 pulses of 1s ON. Moderate improvement with longer pulses
and fewer onsets. <strong>(D)</strong> Long pulse design: 2 pulses of 2s
ON. Minimal improvement due to too few onsets to adequately sample the
kernel. Statistics show events per track, RMSE, power, and duty cycle
for each design.</figcaption>
</figure>
<h1 id="discussion">Discussion</h1>
<h2
id="structural-identifiability-explains-individual-phenotyping-failure">Structural
Identifiability Explains Individual Phenotyping Failure</h2>
<p>The gamma-difference kernel is predominantly inhibitory: for most of
the LED-ON window, the kernel value is negative. The LED stimulus
suppresses reorientation events during LED-ON relative to LED-OFF. The
Fisher information for <span class="math inline">\(\tau_1\)</span> is
proportional to: <span class="math display">\[I(\tau_1) = \int
\frac{1}{\lambda(t;\theta)} \left( \frac{\partial
\lambda(t;\theta)}{\partial \tau_1} \right)^2 dt\]</span> where <span
class="math inline">\(\lambda(t)\)</span> is the instantaneous hazard
rate. Because the kernel is nearly flat and negative for most of the
LED-ON window, the derivative <span class="math inline">\(\partial
\lambda / \partial \tau_1\)</span> is small precisely where informative
events could occur, yielding near-zero information per individual. Data
sparsity compounds the problem: each larva provides few events
distributed across a 6-parameter likelihood surface that is nearly flat
in the <span class="math inline">\(\tau_1\)</span> direction. MLE finds
local optima rather than true parameters.</p>
<h2 id="design-optimization-reveals-regime-dependent-solutions">Design
Optimization Reveals Regime-Dependent Solutions</h2>
<p>The identifiability problem is not simply about event count;
information content per event matters equally. Burst stimulation yields
substantially higher Fisher Information for <span
class="math inline">\(\tau_1\)</span> compared to continuous stimulation
(Figure <a href="#fig:identifiability" data-reference-type="ref"
data-reference="fig:identifiability">5</a>). The mechanism relates to
information localization: the excitatory component peaks early after LED
onset and carries nearly all <span class="math inline">\(\tau_1\)</span>
information. Continuous stimulation samples this early window once per
cycle; burst stimulation samples it multiple times. The systematic
design comparison across kernel regimes (Figure <a
href="#fig:design_comparison" data-reference-type="ref"
data-reference="fig:design_comparison">6</a>) reveals that optimal
protocols depend on whether the kernel is inhibition-dominated or
excitation-dominated.</p>
<p>The optimal design depends on kernel regime. For inhibition-dominated
kernels, burst stimulation is required. For balanced or excitatory
kernels, continuous stimulation is sufficient because higher event rates
provide adequate information. A persistent bias appears at high
excitation-to-inhibition ratios regardless of design, suggesting either
model misspecification or grid boundary effects for excitatory-dominated
kernels.</p>
<h2 id="composite-phenotypes-bypass-kernel-fitting">Composite Phenotypes
Bypass Kernel Fitting</h2>
<p>Given structural identifiability limitations, phenotyping strategies
that bypass full kernel estimation are recommended. The ON/OFF event
rate ratio provides a single-parameter summary estimable even with few
ON-events per larva. First-event latency provides another robust
measure.</p>
<p>Simulation validation reveals asymmetric recoverability. Precision
(modulating ON/OFF hazard ratio) achieves high correlation with true
latent scores even at low event counts, regardless of baseline hazard.
Burstiness (temporal clustering via self-excitation) is more difficult
to recover. At low baseline hazard typical of current data, correlation
with true scores remains poor even at higher event counts. Recovery
improves substantially at higher baseline hazard. The practical
implication is that Precision can be reliably phenotyped from current
data, while Burstiness phenotyping requires either higher stimulus
intensity or burst stimulation protocols.</p>
<h2 id="condition-effects-confound-individual-differences">Condition
Effects Confound Individual Differences</h2>
<p>Variance decomposition analysis revealed that condition effects
account for a substantial portion of <span
class="math inline">\(\tau_1\)</span> variance across the experimental
conditions. Apparent individual differences may reflect condition
assignment rather than true phenotypic variation. Future phenotyping
analyses should either restrict to within-condition comparisons or
explicitly model condition as a covariate.</p>
<h2
id="dataset-composition-explains-population-parameter-differences">Dataset
Composition Explains Population Parameter Differences</h2>
<p>The population-level <span class="math inline">\(\tau_1\)</span>
estimated here differs from the original study. The difference reflects
dataset composition: fewer tracks from fewer experiments in the original
study compared to the broader dataset analyzed here. Estimation method
also differs, with pooled MLE in the original study compared to
hierarchical Bayesian modeling here. The original estimate characterizes
fast response under optimal stimulation conditions; the hierarchical
estimate represents average response across the broader experimental
landscape.</p>
<h2 id="limitations">Limitations</h2>
<p>Data sparsity remains the fundamental limitation. The
data-to-parameter ratio is approximately 3 to 1, far below the 10 to 1
commonly recommended for reliable nonlinear estimation. Power analysis
indicates that substantially more events are needed under continuous
stimulation; burst stimulation reduces this requirement.</p>
<p>The dataset spans multiple experimental conditions with different
<span class="math inline">\(\tau_1\)</span> values. Condition effects
confound individual phenotyping; within-condition analyses are
recommended.</p>
<p>The gamma-difference kernel form may not capture all behavioral
variation. Candidate fast responders require independent replication
before they can be considered established phenotypes.</p>
<h1 id="conclusions">Conclusions</h1>
<h2 id="recommendations-for-future-experiments">Recommendations for
Future Experiments</h2>
<p>For researchers seeking individual-level phenotyping of larval
stimulus-response dynamics, several modifications to standard protocols
are recommended. Continuous 10s ON pulses should be replaced with burst
trains of 10 pulses at 0.5s ON with 0.5s gaps; burst designs provide
higher Fisher Information for <span
class="math inline">\(\tau_1\)</span> and reduce estimation bias
substantially. Recordings should be extended to achieve 50 or more
events per larva with burst stimulation, or 100 or more events with
continuous stimulation. At 1.3 events per minute, reaching 50 events
requires approximately 40 minutes of recording. Model simplification
helps: fixing <span class="math inline">\(\tau_2\)</span>, <span
class="math inline">\(A\)</span>, and <span
class="math inline">\(B\)</span> at population values and estimating
only <span class="math inline">\(\tau_1\)</span> per individual reduces
the per-larva parameter count from 6 to 1, improving identifiability
proportionally. Phenotyping should be conducted within a single,
well-defined stimulus condition because between-condition variance
confounds individual-level inference.</p>
<h2 id="recommended-phenotyping-approach">Recommended Phenotyping
Approach</h2>
<p>Given experimental constraints, composite phenotypes offer a
practical alternative to kernel parameter estimation. The recommended
approach involves computing seven behavioral measures per larva,
including ON/OFF event rate ratio, first-event latency, IEI-CV, Fano
factor, response reliability, habituation slope, and phase coherence.
Factor analysis then extracts two latent dimensions: Precision for
timing accuracy and Burstiness for temporal irregularity. The resulting
factor scores serve as continuous phenotypes for downstream analysis,
including heritability estimation, genetic association, and neural
correlate mapping.</p>
<p>Simulation validation confirms that Precision is recoverable with
approximately 25 events per larva under current protocols. Burstiness
requires higher event counts or burst stimulation designs.</p>
<h2 id="validation-requirements">Validation Requirements</h2>
<p>Any putative phenotype identified through clustering or hierarchical
modeling requires validation. Round-trip validation ARI should be
reported, with values below 0.5 indicating unreliable recovery. Power
analysis determines whether the study can detect true differences; power
below 50% means most true phenotypes are missed. Gap statistic reveals
whether clustering is justified, with optimal <span
class="math inline">\(k=1\)</span> suggesting continuous rather than
discrete variation. Independent replication should be required before
treating candidates as established phenotypes.</p>
<h2 id="methodological-contribution">Methodological Contribution</h2>
<p>The present study establishes quantitative guidelines for larval
phenotyping, including minimum event counts, optimal stimulation
designs, and validation metrics. Population-level analysis remains
robust under current protocols. Individual-level analysis requires
either protocol modifications such as burst stimulation and longer
recordings, or alternative phenotyping strategies such as composite
scores rather than kernel parameters.</p>
<p>The analytical framework developed here, including Fisher Information
analysis, design sweeps, power curves, and validation cascades, is
applicable to other sparse point-process phenotyping problems in
behavioral neuroscience.</p>
<h1 id="app:clustering">Detailed Clustering Methodology</h1>
<h2 id="clustering-stability-analysis">Clustering Stability
Analysis</h2>
<p>K-means clustering was performed on standardized kernel features
(<span class="math inline">\(\tau_1\)</span>, <span
class="math inline">\(\tau_2\)</span>, <span
class="math inline">\(A\)</span>, <span
class="math inline">\(B\)</span>) for <span class="math inline">\(k = 2,
3, 4, 5\)</span> clusters. Stability was assessed via bootstrap
resampling (50 iterations) with Adjusted Rand Index (ARI).</p>
<h3 id="simulated-data-results">Simulated Data Results</h3>
<p>On 300 simulated tracks, clustering stability increased monotonically
with <span class="math inline">\(k\)</span>:</p>
<div id="tab:sim_clustering_app">
<table>
<caption>Clustering stability on simulated data (N=300 tracks)</caption>
<thead>
<tr>
<th style="text-align: center;"><strong>k</strong></th>
<th style="text-align: center;"><strong>Silhouette</strong></th>
<th style="text-align: center;"><strong>Stability (ARI)</strong></th>
<th style="text-align: center;"><strong>Cluster Sizes</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.760</td>
<td style="text-align: center;">0.513 <span
class="math inline">\(\pm\)</span> 0.506</td>
<td style="text-align: center;">{294, 6}</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.497</td>
<td style="text-align: center;">0.703 <span
class="math inline">\(\pm\)</span> 0.357</td>
<td style="text-align: center;">{75, 6, 219}</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.501</td>
<td style="text-align: center;">0.841 <span
class="math inline">\(\pm\)</span> 0.218</td>
<td style="text-align: center;">{70, 220, 6, 4}</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.471</td>
<td style="text-align: center;"><strong>0.920</strong> <span
class="math inline">\(\pm\)</span> 0.099</td>
<td style="text-align: center;">{153, 6, 65, 72, 4}</td>
</tr>
</tbody>
</table>
</div>
<p>The high silhouette score for <span
class="math inline">\(k=2\)</span> was driven by separation of 6 outlier
tracks from the 294-track majority. The <span
class="math inline">\(k=5\)</span> solution showed highest stability
(ARI = 0.920) with lowest variance.</p>
<h3 id="empirical-data-results">Empirical Data Results</h3>
<div id="tab:emp_clustering_app">
<table>
<caption>Clustering stability on empirical data (N=260 tracks)</caption>
<thead>
<tr>
<th style="text-align: center;"><strong>k</strong></th>
<th style="text-align: center;"><strong>Silhouette</strong></th>
<th style="text-align: center;"><strong>Stability (ARI)</strong></th>
<th style="text-align: center;"><strong>Cluster Sizes</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.435</td>
<td style="text-align: center;">0.478 <span
class="math inline">\(\pm\)</span> 0.500</td>
<td style="text-align: center;">{140, 120}</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.503</td>
<td style="text-align: center;">0.918 <span
class="math inline">\(\pm\)</span> 0.200</td>
<td style="text-align: center;">{11, 129, 120}</td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.539</td>
<td style="text-align: center;"><strong>0.945</strong> <span
class="math inline">\(\pm\)</span> 0.104</td>
<td style="text-align: center;">{128, 11, 115, 6}</td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;"><strong>0.573</strong></td>
<td style="text-align: center;">0.937 <span
class="math inline">\(\pm\)</span> 0.089</td>
<td style="text-align: center;">{115, 11, 68, 6, 60}</td>
</tr>
</tbody>
</table>
</div>
<h2 id="cluster-validation-results">Cluster Validation Results</h2>
<div id="tab:validation_app">
<table>
<caption>Statistical validation of empirical phenotype
clusters</caption>
<thead>
<tr>
<th style="text-align: center;"><strong>k</strong></th>
<th style="text-align: center;"><strong>Permutation p</strong></th>
<th style="text-align: center;"><strong>Gap Optimal?</strong></th>
<th style="text-align: center;"><strong>Train/Test ARI</strong></th>
<th style="text-align: center;"><strong>Validated?</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">2</td>
<td style="text-align: center;">0.022*</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">0.15 (Poor)</td>
<td style="text-align: center;">Partial</td>
</tr>
<tr>
<td style="text-align: center;">3</td>
<td style="text-align: center;">0.002**</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">0.74 (Good)</td>
<td style="text-align: center;"><strong>Yes</strong></td>
</tr>
<tr>
<td style="text-align: center;">4</td>
<td style="text-align: center;"><span
class="math inline">\(&lt;\)</span>0.001***</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">0.79 (Good)</td>
<td style="text-align: center;"><strong>Yes</strong></td>
</tr>
<tr>
<td style="text-align: center;">5</td>
<td style="text-align: center;"><span
class="math inline">\(&lt;\)</span>0.001***</td>
<td style="text-align: center;">No</td>
<td style="text-align: center;">0.78 (Good)</td>
<td style="text-align: center;"><strong>Yes</strong></td>
</tr>
</tbody>
</table>
</div>
<p>The gap statistic indicated optimal <span
class="math inline">\(k=1\)</span>, suggesting continuous variation
rather than discrete subpopulations.</p>
<h1 id="app:fno">Neural Operator Analysis</h1>
<p>Given limitations of parametric fitting, a Fourier Neural Operator
(FNO) was trained to learn the mapping from PSTH to kernel shape
directly.</p>
<h2 id="validation-on-synthetic-data">Validation on Synthetic Data</h2>
<p>The FNO was trained on 2000 synthetic tracks with known ground-truth
kernels.</p>
<table>
<caption>Kernel recovery performance on synthetic validation
data</caption>
<thead>
<tr>
<th style="text-align: left;"><strong>Model</strong></th>
<th style="text-align: center;"><strong>Kernel Correlation
(r)</strong></th>
<th style="text-align: center;"><strong>MSE</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">FNO</td>
<td style="text-align: center;">0.921</td>
<td style="text-align: center;">0.103</td>
</tr>
<tr>
<td style="text-align: left;">MLP baseline</td>
<td style="text-align: center;">0.978</td>
<td style="text-align: center;">0.035</td>
</tr>
</tbody>
</table>
<h2 id="application-to-empirical-data">Application to Empirical
Data</h2>
<table>
<caption>Clustering of FNO-derived kernels</caption>
<thead>
<tr>
<th style="text-align: left;"><strong>k</strong></th>
<th style="text-align: center;"><strong>Silhouette</strong></th>
<th style="text-align: center;"><strong>ARI vs PSTH</strong></th>
<th style="text-align: center;"><strong>ARI vs Parametric</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">3</td>
<td style="text-align: center;">0.326</td>
<td style="text-align: center;">0.250</td>
<td style="text-align: center;">0.011</td>
</tr>
<tr>
<td style="text-align: left;">4</td>
<td style="text-align: center;">0.303</td>
<td style="text-align: center;">0.276</td>
<td style="text-align: center;">0.011</td>
</tr>
<tr>
<td style="text-align: left;">5</td>
<td style="text-align: center;">0.255</td>
<td style="text-align: center;">0.200</td>
<td style="text-align: center;">0.011</td>
</tr>
</tbody>
</table>
<p>The near-zero ARI between FNO-derived and parametric clusters
indicates that parametric fitting creates artifacts unrelated to
behavioral structure.</p>
<h1 id="app:roundtrip">Round-Trip Validation Protocol</h1>
<p>To test whether identified phenotypes represent recoverable
individual differences, round-trip validation was performed.</p>
<h2 id="simulation-protocol">Simulation Protocol</h2>
<p>A total of 260 synthetic tracks were generated. Each track was
assigned to a phenotype cluster based on empirical proportions. Kernel
parameters were sampled from that cluster’s distribution. Reorientation
events were simulated via discrete-time Bernoulli process with <span
class="math inline">\(p(t) = \exp(\beta_0 + K(t))\)</span>. Kernels were
then fitted to the simulated events and the fitted parameters were
clustered for comparison to ground truth.</p>
<h2 id="results-1">Results</h2>
<div id="tab:roundtrip_app">
<table>
<caption>Round-trip simulation validation results</caption>
<thead>
<tr>
<th style="text-align: left;"><strong>Metric</strong></th>
<th style="text-align: center;"><strong>Observed</strong></th>
<th style="text-align: center;"><strong>Expected</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Fit success rate</td>
<td style="text-align: center;">98.8%</td>
<td style="text-align: center;"><span
class="math inline">\(&gt;\)</span>90% (pass)</td>
</tr>
<tr>
<td style="text-align: left;">Cluster recovery (ARI)</td>
<td style="text-align: center;"><strong>0.128</strong></td>
<td style="text-align: center;"><span
class="math inline">\(&gt;\)</span>0.5 (FAIL)</td>
</tr>
<tr>
<td style="text-align: left;"><span
class="math inline">\(\tau_1\)</span> correlation</td>
<td style="text-align: center;">-0.03</td>
<td style="text-align: center;"><span
class="math inline">\(&gt;\)</span>0.5 (FAIL)</td>
</tr>
<tr>
<td style="text-align: left;"><span
class="math inline">\(\tau_2\)</span> correlation</td>
<td style="text-align: center;"><strong>-0.62</strong></td>
<td style="text-align: center;"><span
class="math inline">\(&gt;\)</span>0.5 (FAIL)</td>
</tr>
<tr>
<td style="text-align: left;"><span class="math inline">\(A\)</span>
correlation</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;"><span
class="math inline">\(&gt;\)</span>0.5 (FAIL)</td>
</tr>
<tr>
<td style="text-align: left;"><span class="math inline">\(B\)</span>
correlation</td>
<td style="text-align: center;">-0.01</td>
<td style="text-align: center;"><span
class="math inline">\(&gt;\)</span>0.5 (FAIL)</td>
</tr>
</tbody>
</table>
</div>
<p>The near-zero or negative parameter correlations indicate that kernel
fitting from sparse event data cannot reliably recover ground-truth
parameters.</p>
<h1 id="app:pca">PCA Representation Comparison</h1>
<p>To investigate whether phenotype clusters reflect genuine behavioral
variation, clustering was compared in two representations: PSTH-based
(raw event patterns binned in 0.5s intervals, 0-10s post-LED onset, 20
dimensions) and kernel-based (fitted parameters <span
class="math inline">\(\tau_1\)</span>, <span
class="math inline">\(\tau_2\)</span>, <span
class="math inline">\(A\)</span>, <span
class="math inline">\(B\)</span>, 4 dimensions).</p>
<table>
<caption>PCA comparison of representations</caption>
<thead>
<tr>
<th style="text-align: left;"><strong>Metric</strong></th>
<th style="text-align: center;"><strong>PSTH</strong></th>
<th style="text-align: center;"><strong>Kernel</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">PC1 variance explained</td>
<td style="text-align: center;">15%</td>
<td style="text-align: center;">39%</td>
</tr>
<tr>
<td style="text-align: left;">PCs for 90% variance</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">4</td>
</tr>
<tr>
<td style="text-align: left;">Silhouette (k=4)</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.54</td>
</tr>
</tbody>
</table>
<p>When clustering was performed independently on each representation,
the resulting cluster assignments showed essentially no agreement with
an Adjusted Rand Index of 0.01 at k=4. Individuals clustered together by
kernel parameters are not clustered together by event patterns.</p>
<h1 id="app:enhancements">Statistical Enhancement Details</h1>
<h2 id="power-analysis">Power Analysis</h2>
<p>The simulation-based power analysis answered how many events per
larva are needed to reliably detect a fast responder. Power increased
monotonically with event count: at 25 events (current data) power was
approximately 20–30%, at 100 events power reached 75–85%, and at 150
events power exceeded 90%. Type I error remained controlled near the
nominal 5% level across all event counts tested.</p>
<h2 id="posterior-predictive-checks">Posterior Predictive Checks</h2>
<p>The hierarchical Bayesian model passed PPC with <span
class="math inline">\(&gt;\)</span>90% of tracks showing observed event
patterns consistent with posterior predictions for event count, mean
ISI, and PSTH shape.</p>
<h2 id="model-comparison">Model Comparison</h2>
<p>Model comparison between the full 6-parameter and reduced 2-parameter
models demonstrated that the reduced model is preferred for the majority
of tracks. The reduced model achieved lower BIC in <span
class="math inline">\(&gt;\)</span>60% of tracks.</p>
<h2 id="cross-experiment-generalization">Cross-Experiment
Generalization</h2>
<p>Leave-one-experiment-out cross-validation assessed population
parameter stability across 14 experiments. The coefficient of variation
for <span class="math inline">\(\tau_1\)</span> across folds was <span
class="math inline">\(&lt;\)</span>15%.</p>
<h1 class="unnumbered" id="acknowledgments">Acknowledgments</h1>
<p>We thank the members of the laboratory for helpful discussions and
feedback on the manuscript.</p>
<h1 class="unnumbered" id="data-availability">Data Availability</h1>
<p>All data and analysis code are available in the project repository.
Processed data are stored in HDF5 format. Analysis scripts are written
in Python with NumPy, SciPy, scikit-learn, and NumPyro dependencies.</p>
<h1 id="references">References</h1>
<div class="thebibliography">
<p><span>9</span></p>
<p>Tibshirani, R., Walther, G., &amp; Hastie, T. (2001). Estimating the
number of clusters in a data set via the gap statistic. <em>Journal of
the Royal Statistical Society: Series B (Statistical Methodology)</em>,
63(2), 411-423.</p>
<p>Hubert, L., &amp; Arabie, P. (1985). Comparing partitions.
<em>Journal of Classification</em>, 2(1), 193-218.</p>
<p>Rousseeuw, P. J. (1987). Silhouettes: A graphical aid to the
interpretation and validation of cluster analysis. <em>Journal of
Computational and Applied Mathematics</em>, 20, 53-65.</p>
<p>Pulver, S. R., Bayraktar, E., Petrossian, B., &amp; Kaiser, M.
(2018). Monitoring brain activity and behavior in freely behaving
Drosophila larvae using bioluminescence. <em>Scientific Reports</em>,
8(1), 10410.</p>
<p>Szuperak, M., Churgin, M. A., Borja, A. J., Raizen, D. M., Bhatt, A.
S., Kayser, M. S., &amp; Bhatt, P. J. (2018). A sleep state in
Drosophila larvae required for neural stem cell proliferation.
<em>eLife</em>, 7, e33220.</p>
<p>Gelman, A., &amp; Hill, J. (2006). <em>Data Analysis Using Regression
and Multilevel/Hierarchical Models</em>. Cambridge University Press.</p>
<p>Betancourt, M. (2017). A conceptual introduction to Hamiltonian Monte
Carlo. <em>arXiv preprint arXiv:1701.02434</em>.</p>
<p>Shimazaki, H., &amp; Shinomoto, S. (2007). A method for selecting the
bin size of a time histogram. <em>Neural Computation</em>, 19(6),
1503-1527.</p>
<p>Gerstein, G. L., &amp; Kiang, N. Y. (1960). An approach to the
quantitative analysis of electrophysiological data from single neurons.
<em>Biophysical Journal</em>, 1(1), 15-28.</p>
<p>Perkel, D. H., Gerstein, G. L., &amp; Moore, G. P. (1967). Neuronal
spike trains and stochastic point processes: I. The single spike train.
<em>Biophysical Journal</em>, 7(4), 391-418.</p>
<p>Daley, D. J., &amp; Vere-Jones, D. (2003). <em>An Introduction to the
Theory of Point Processes, Volume I: Elementary Theory and Methods</em>.
Springer.</p>
<p>Heckman, J., &amp; Singer, B. (1984). The identifiability of the
proportional hazard model. <em>The Review of Economic Studies</em>,
51(2), 231-241.</p>
<p>Rebora, P., Salim, A., &amp; Reilly, M. (2014). bshazard: A flexible
tool for nonparametric smoothing of the hazard function. <em>The R
Journal</em>, 6(2), 114-122.</p>
<p>Salehi, F., Trouleau, W., Grossglauser, M., &amp; Thiran, P. (2019).
Learning Hawkes processes from a handful of events. <em>Advances in
Neural Information Processing Systems</em>, 32.</p>
<p>Du, N., Dai, H., Trivedi, R., Upadhyay, U., Gomez-Rodriguez, M.,
&amp; Song, L. (2016). Recurrent marked temporal point processes:
Embedding event history to vector. <em>Proceedings of the 22nd ACM
SIGKDD International Conference on Knowledge Discovery and Data
Mining</em>, 1555-1564.</p>
<p>Wang, J.-L., Müller, H.-G., &amp; Eubank, R. L. (1996). Hazard rate
regression using ordinary nonparametric regression smoothers.
<em>Journal of Computational and Graphical Statistics</em>, 5(3),
195-212.</p>
</div>
</body>
</html>
